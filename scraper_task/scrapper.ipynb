{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(html_soup, url, catalogue):\n",
    "    for book in html_soup.select('article.product_pod'):\n",
    "        book_url = book.find('h3').find('a').get('href')\n",
    "        book_url = urljoin(url, book_url)\n",
    "        path = urlparse(book_url).path\n",
    "        book_id = path.split('/')[2] \n",
    "        catalogue[book_id] = {}    \n",
    "    return catalogue    \n",
    "\n",
    "\n",
    "def scrape_book(html_soup, book_id):\n",
    "    main = html_soup.find(class_='product_main')\n",
    "    book = {}\n",
    "    book['title'] = main.find('h1').get_text(strip=True)\n",
    "    book['price'] = main.find(class_='price_color').get_text(strip=True)\n",
    "    book['rating'] = ' '.join(main.find(class_='star-rating') \\\n",
    "                        .get('class')).replace('star-rating', '').strip()\n",
    "    \n",
    "    desc = html_soup.find(id='product_description')\n",
    "    book['description'] = ''\n",
    "    if desc:\n",
    "        book['description'] = desc.find_next_sibling('p') \\\n",
    "                                  .get_text(strip=True)\n",
    "    book_product_table = html_soup.find(text='Product Information').find_next('table')\n",
    "    for row in book_product_table.find_all('tr'):\n",
    "        header = row.find('th').get_text(strip=True)\n",
    "        header = re.sub('[^a-zA-Z]+', '_', header)\n",
    "        value = row.find('td').get_text(strip=True)\n",
    "        if header == 'UPC':\n",
    "            book[header] = value\n",
    "    return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-scrape the catalogue (y/n)? n\n",
      "Now scraping book: http://books.toscrape.com/catalogue/a-light-in-the-attic_1000\n",
      "Now scraping book: http://books.toscrape.com/catalogue/tipping-the-velvet_999\n",
      "Now scraping book: http://books.toscrape.com/catalogue/soumission_998\n",
      "Now scraping book: http://books.toscrape.com/catalogue/sharp-objects_997\n",
      "Now scraping book: http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996\n",
      "Now scraping book: http://books.toscrape.com/catalogue/the-requiem-red_995\n",
      "Now scraping book: http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994\n",
      "Now scraping book: http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993\n",
      "Now scraping book: http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992\n",
      "Now scraping book: http://books.toscrape.com/catalogue/the-black-maria_991\n",
      "Now scraping book: http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990\n"
     ]
    }
   ],
   "source": [
    "# Scrape the pages in the catalogue\n",
    "catalogue = {}\n",
    "base_url = 'http://books.toscrape.com/'\n",
    "catalogue_path = 'catalogue.json'\n",
    "if os.path.exists(catalogue_path):\n",
    "    with open(catalogue_path) as json_file:\n",
    "        catalogue = json.load(json_file)\n",
    "url = base_url\n",
    "inp = input('Re-scrape the catalogue (y/n)? ')\n",
    "while True and inp == 'y':\n",
    "    print('Now scraping page:', url)\n",
    "    r = requests.get(url)\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    catalogue = scrape_books(html_soup, url, catalogue)\n",
    "    next_a = html_soup.select('li.next > a')\n",
    "    if not next_a or not next_a[0].get('href'):\n",
    "        break\n",
    "    url = urljoin(url, next_a[0].get('href'))\n",
    "if inp == 'y':\n",
    "    with open('catalogue.json', 'w') as json_file:\n",
    "            json.dump(catalogue, json_file)    \n",
    "        \n",
    "books = []\n",
    "for book_id in catalogue.keys():\n",
    "    book_url = base_url + 'catalogue/{}'.format(book_id)\n",
    "    print('Now scraping book:', book_url)\n",
    "    r = requests.get(book_url)\n",
    "    r.encoding = 'utf-8'\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    dictionary = scrape_book(html_soup, book_id)\n",
    "    books.append(dictionary)\n",
    "df = pd.DataFrame(books)\n",
    "df.to_csv('result_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
